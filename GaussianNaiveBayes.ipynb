{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "#Update mean and variance\n",
    "def update_mean_variance(x):\n",
    "    mean = np.mean(x, axis=0)\n",
    "    variance = np.var(x, axis=0)\n",
    "    return mean, variance\n",
    "\n",
    "#Training data\n",
    "def fit(X_train, y_train):\n",
    "    categories = np.unique(y_train)\n",
    "    means = np.zeros((len(categories), X_train.shape[1]))\n",
    "    variances = np.zeros((len(categories), X_train.shape[1]))\n",
    "    category_ratios = []\n",
    "    for category in categories:\n",
    "        category_index = categories.searchsorted(category)\n",
    "        category_data = X_train[y_train == category]\n",
    "        category_ratio = category_data.shape[0]/X_train.shape[0]\n",
    "        means[category_index, :], variances[category_index, :] = update_mean_variance(category_data)\n",
    "        category_ratios.append(category_ratio)\n",
    "    return means, variances, category_ratios\n",
    "\n",
    "#Gauss distribution function\n",
    "def gaussian(x, mean, variance):\n",
    "    return (1 / (np.sqrt(2 * np.pi * variance))) * np.exp(-(np.square(x - mean) / (2 * variance)))\n",
    "\n",
    "#The probability corresponding to each group of data in each category\n",
    "def probability_of_each_data(X_test, mean, variance,category_ratio):\n",
    "    p = []\n",
    "    features = range(X_test.shape[1])\n",
    "    for indexs in X_test.index:\n",
    "        if category_ratio != 0:\n",
    "            probability = np.log(category_ratio)\n",
    "            row_data = X_test.loc[indexs].values[:]\n",
    "            for i in features:\n",
    "                probability += np.log(gaussian(row_data[i], mean[i], variance[i]))\n",
    "        else:\n",
    "            probability = 0\n",
    "        p.append(probability)\n",
    "    return p\n",
    "\n",
    "#Corresponding probabilities for each category\n",
    "def probability_of_each_category(X_test, category_total, means, variances, category_ratios):\n",
    "    probability = []\n",
    "    for i in range(category_total):\n",
    "        mean, variance = means[i, :], variances[i, :]\n",
    "        probability.append(probability_of_each_data(X_test, mean, variance,category_ratios[i]))\n",
    "    return np.array(probability).T\n",
    "\n",
    "#Predict data\n",
    "def predict(X_test, y_test, means, variances, category_ratios):\n",
    "    probability = probability_of_each_category(X_test, len(np.unique(y_test)), means, variances, category_ratios)\n",
    "    print (np.unique(y_test)[np.argmax(probability, axis=1)])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('d:/iris.csv')\n",
    "    class_features = [\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\"]\n",
    "    X_train = data[class_features]\n",
    "    y_train = data[\"Species\"]\n",
    "    means, variances, category_ratios = fit(X_train, y_train)\n",
    "    X_test = DataFrame({'Sepal.Length':[3.1], 'Sepal.Width':[4.4], 'Petal.Length':[2.1], 'Petal.Width':[0.2]})\n",
    "    predict(X_test, y_train, means, variances,category_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
